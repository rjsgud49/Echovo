import React, { useEffect, useRef, useState } from 'react';
import Recorder from './Recorder';
import type { RecorderHandle } from './Recorder';
import { generateQuestion, getScoredFeedback, transcribeAudio, summarizeQuestion } from '../utils/openai';
import type { RecordItem, Props } from '../types/interview';
import {MessageCircle } from 'lucide-react';

const InterviewBox: React.FC<Props> = ({ field: propField, stack: propStack, onLogUpdated }) => {
    const [question, setQuestion] = useState('');
    const [answer, setAnswer] = useState('');
    const [feedback, setFeedback] = useState('');
    const [modelAnswer, setModelAnswer] = useState('');
    const [liveTranscript, setLiveTranscript] = useState('');
    const [recording, setRecording] = useState(false);
    // const [seconds, setSeconds] = useState(0);
    const [isSaving, setIsSaving] = useState(false);
    const [isDuplicate, setIsDuplicate] = useState(false);
    const [questionReady, setQuestionReady] = useState(false);

    const [field, setField] = useState('');
    const [stack, setStack] = useState('');

    const recorderRef = useRef<RecorderHandle>(null);
    const recognitionRef = useRef<SpeechRecognition | null>(null);
    const isRecognitionStoppedByUser = useRef(false);
    const streamRef = useRef<MediaStream | null>(null);
    const startTimeRef = useRef<number | null>(null);
    const recordingDurationRef = useRef<number>(0);

    useEffect(() => {
        const setup = async () => {
            let f = propField;
            let s = propStack;
            if (!f || !s) {
                const saved = localStorage.getItem('interviewUserInfo');
                if (saved) {
                    const parsed = JSON.parse(saved);
                    f = parsed.field;
                    s = parsed.stack;
                }
            }
            setField(f ?? '');
            setStack(s ?? '');

            if (f && s) {
                const q = await generateQuestion(f, s);
                setQuestion(q);
                setQuestionReady(true);
            }
        };
        setup();
    }, [propField, propStack]);

    // useEffect(() => {
    //     let timer: ReturnType<typeof setInterval>;
    //     if (recording) {
    //         timer = setInterval(() => setSeconds((prev) => prev + 1), 1000);
    //     } else {
    //         setSeconds(0);
    //     }
    //     return () => clearInterval(timer);
    // }, [recording]);

    const startSpeechRecognition = () => {
        const SpeechRecognitionConstructor =
            window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognitionConstructor) {
            alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
            return;
        }

        const recognition = new (SpeechRecognitionConstructor as unknown as new () => SpeechRecognition)();
        recognition.lang = 'ko-KR';
        recognition.interimResults = true;

        recognition.onresult = (event: SpeechRecognitionEvent) => {
            let text = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (!event.results[i].isFinal) {
                    text += event.results[i][0].transcript;
                }
            }
            setLiveTranscript(text);
        };

        recognition.onend = () => {
            if (!isRecognitionStoppedByUser.current) {
                recognition.start(); // ìë™ ì¬ì‹œì‘ (ìˆ˜ë™ ì¤‘ì§€ ì•„ë‹ ë•Œë§Œ)
            } else {
                console.log('ğŸ¤ ì‚¬ìš©ìê°€ ìŒì„± ì¸ì‹ì„ ìˆ˜ë™ìœ¼ë¡œ ì¤‘ì§€í–ˆê¸° ë•Œë¬¸ì— ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ');
            }
        };

        recognition.onerror = (event) => {
            console.error('ğŸ¤ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
        };

        isRecognitionStoppedByUser.current = false; // ìë™ ì¬ì‹œì‘ í—ˆìš©
        recognitionRef.current = recognition;
        recognition.start();
    };

    // stop í•¨ìˆ˜
    const stopSpeechRecognition = () => {
        isRecognitionStoppedByUser.current = true;
        if (recognitionRef.current) {
            recognitionRef.current.stop(); // ì¼ë‹¨ ì •ì§€ ìš”ì²­ë§Œ í•¨
            // recognitionRef.current = null; âŒ ì—¬ê¸°ì„œ ì§€ìš°ì§€ ë§ê³ ...
        }
    };

    if (recognitionRef.current) {
        recognitionRef.current.onend = () => {
            if (!isRecognitionStoppedByUser.current) {
                recognitionRef.current?.start(); // ì•ˆì „í•˜ê²Œ ì¬ì‹œì‘
            } else {
                recognitionRef.current = null;
            }
        };
    }






    const startRecording = async () => {
        console.log('â–¶ï¸ ë…¹ìŒ ì‹œì‘');

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            streamRef.current = stream;
            const track = stream.getAudioTracks()[0];
            if (!track) {
                alert('ë§ˆì´í¬ ì¥ì¹˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
                return;
            }

            startSpeechRecognition();

            recorderRef.current?.start(stream);
            startTimeRef.current = Date.now();
            setRecording(true);
            setAnswer('');
            setFeedback('');
            setModelAnswer('');
            setLiveTranscript('');
        } catch (err) {
            console.error('ğŸ™ï¸ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', err);
            alert('ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        }
    };

    const stopRecording = () => {
        console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€');
        recorderRef.current?.stop();
        stopSpeechRecognition();
        setRecording(false);

        if (startTimeRef.current) {
            recordingDurationRef.current = Math.floor((Date.now() - startTimeRef.current) / 1000);
        }

        if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
            console.log('ğŸ”Œ ë§ˆì´í¬ stream í•´ì œ ì™„ë£Œ');
        }
    };

    const handleRecordingStop = async (blob: Blob) => {
        console.log('ğŸ“¦ handleRecordingStop triggered');
        setIsSaving(true);
        const transcript = await transcribeAudio(blob);
        const summary = await summarizeQuestion(question);
        const { feedback: fb, score, modelAnswer: example } = await getScoredFeedback(question, transcript, field);
        if (!transcript?.trim() || !fb?.trim()) {
            setIsSaving(false);
            return;
        }

        const prev = JSON.parse(localStorage.getItem('interviewLogs') || '[]') as RecordItem[];
        const alreadyExists = prev.some((log) => log.question === question);
        if (alreadyExists) {
            setIsDuplicate(true);
            setIsSaving(false);
            return;
        }

        const record: RecordItem = {
            id: Date.now().toString(),
            date: new Date().toLocaleString('ko-KR', { hour12: false }),
            question,
            summary,
            answer: transcript,
            feedback: fb,
            modelAnswer: example,
            score,
            duration: recordingDurationRef.current,
        };

        try {
            localStorage.setItem('interviewLogs', JSON.stringify([record, ...prev]));
            onLogUpdated?.();
        } catch (e) {
            console.error('âŒ ì €ì¥ ì‹¤íŒ¨:', e);
        }

        setAnswer(transcript);
        setFeedback(fb);
        setModelAnswer(example);
        setLiveTranscript('');
        setIsSaving(false);
        setIsDuplicate(true);
    };

    const regenerateQuestion = async () => {
        setQuestionReady(false);
        setIsDuplicate(false);
        setAnswer('');
        setFeedback('');
        setModelAnswer('');
        setLiveTranscript('');
        const q = await generateQuestion(field, stack);
        setQuestion(q);
        setQuestionReady(true);
    };

    return (
        <div className="flex flex-col items-center justify-start min-h-screen p-8 bg-gray-50 text-center space-y-8">
            <div className="bg-white rounded-2xl shadow-lg border border-gray-100 p-8 mb-8 max-w-4xl min-w-4xl w-full mx-auto">
                <div className="flex items-start space-x-4">
                    <div className="w-12 h-12 bg-gradient-to-r from-amber-400 to-orange-500 rounded-xl flex items-center justify-center flex-shrink-0">
                        <MessageCircle className="w-6 h-6 text-white" />
                    </div>
                    <div>
                        <h2 className="text-lg font-semibold text-gray-900 mb-2"></h2>
                        <p className="text-gray-700 text-lg leading-relaxed">
                            {questionReady && question?.trim()
                                ? question
                                : 'â³ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...'}
                        </p>
                    </div>
                </div>
            </div>

            {/* ë…¹ìŒ ë²„íŠ¼ì€ ì§ˆë¬¸ ì¤€ë¹„ ì™„ë£Œ && ì¤‘ë³µ ì§ˆë¬¸ ì•„ë‹˜ && í”¼ë“œë°± ìƒì„± ì¤‘ ì•„ë‹˜ì¼ ë•Œë§Œ */}
            {questionReady && !isDuplicate && !isSaving && (
                <button
                    className={`w-[150px] h-[150px] rounded-full text-white text-xl font-bold shadow transition ${recording ? 'bg-red-500 hover:bg-red-600' : 'bg-green-500 hover:bg-green-600'}`}
                    onClick={recording ? stopRecording : startRecording}
                    disabled={answer !== ''}
                >
                    {recording ? 'ì¤‘ì§€í•˜ê¸°' : 'ì‹œì‘í•˜ê¸°'}
                </button>
            )}

            {/* ì§ˆë¬¸ ì¤€ë¹„ ì¤‘ì´ê±°ë‚˜ í”¼ë“œë°± ìƒì„± ì¤‘ì¼ ë•Œ ë©”ì‹œì§€ ì¶œë ¥ */}
            {(!questionReady || isSaving) && (
                <h2 className="text-sm text-gray-500">
                    {!questionReady
                        ? ''
                        : isSaving
                            ? 'ğŸ’­ í”¼ë“œë°± ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...'
                            : ''}
                </h2>
            )}

            {recording && (
                <div className="text-gray-700 space-y-2">
                    {liveTranscript && (
                        <p className="text-sm text-gray-600">ğŸ¤ <strong>ì‹¤ì‹œê°„:</strong> {liveTranscript}</p>
                    )}
                </div>
            )}

            {!recording && isDuplicate && (
                <button
                    onClick={regenerateQuestion}
                    className="mt-2 px-6 py-3 bg-blue-500 hover:bg-blue-600 text-white font-semibold rounded shadow"
                >
                    ğŸ”„ ë‹¤ìŒ ì§ˆë¬¸ ìš”ì²­
                </button>
            )}

            <div className="text-left max-w-3xl space-y-4 mt-8">
                {answer && <p><strong>ğŸ“ ë‚´ ë‹µë³€:</strong> {answer}</p>}
                {feedback && <p><strong>ğŸ’¡ í”¼ë“œë°±:</strong> {feedback}</p>}
                {modelAnswer && <p><strong>ğŸ“˜ ëª¨ë²”ë‹µì•ˆ:</strong> {modelAnswer}</p>}
            </div>

            <Recorder ref={recorderRef} onStop={handleRecordingStop} maxDuration={60} />
        </div>
    );

};

export default InterviewBox;
