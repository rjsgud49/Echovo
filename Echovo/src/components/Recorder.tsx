// âœ… src/components/Recorder.tsx
import { forwardRef, useImperativeHandle, useRef, useState, useEffect } from 'react';

// Recorder.tsx
export interface RecorderHandle {
    start: (stream: MediaStream) => void;
    stop: () => void;
}


interface RecorderProps {
    onStop: (blob: Blob) => void;
    maxDuration?: number;
}

const Recorder = forwardRef<RecorderHandle, RecorderProps>(({ onStop, maxDuration = 60 }, ref) => {
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const chunksRef = useRef<Blob[]>([]);
    const timerRef = useRef<number | null>(null);
    const intervalRef = useRef<number | null>(null);
    const streamRef = useRef<MediaStream | null>(null); // ì¶”ê°€

    const [elapsedTime, setElapsedTime] = useState(0);
    const [recording, setRecording] = useState(false);

    useImperativeHandle(ref, () => ({
        start,
        stop,
    }));

    useEffect(() => {
        if (recording) {
            console.log('â±ï¸ íƒ€ì´ë¨¸ ì‹œì‘');
            intervalRef.current = window.setInterval(() => {
                setElapsedTime((prev) => {
                    if (prev + 1 >= maxDuration) {
                        stop();
                    }
                    return prev + 1;
                });
            }, 1000);

            timerRef.current = window.setTimeout(() => stop(), maxDuration * 1000);
        }

        return () => clearTimers();
    }, [recording]);

    const clearTimers = () => {
        if (timerRef.current) clearTimeout(timerRef.current);
        if (intervalRef.current) clearInterval(intervalRef.current);
    };

    const start = async () => {
        if (recording) {
            console.log('â›” ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ë¼ start() ë¬´ì‹œë¨');
            return;
        }

        console.log('â–¶ï¸ MediaRecorder start() í˜¸ì¶œë¨');

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            streamRef.current = stream;
            console.log('âœ… ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ í™•ë³´ë¨', stream);

            const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

            recorder.ondataavailable = (e) => {
                console.log('ğŸ™ï¸ ë°ì´í„° ë°œìƒ', e.data);
                if (e.data.size > 0) {
                    chunksRef.current.push(e.data);
                }
            };

            recorder.onstop = () => {
                console.log('ğŸ“¦ Recorder onstop triggered');
                const blob = new Blob(chunksRef.current, { type: 'audio/webm' });
                console.log('ğŸ“¦ Blob ìƒì„±ë¨:', blob);
                chunksRef.current = [];
                onStop(blob);
                setRecording(false);
                setElapsedTime(0);
            };

            mediaRecorderRef.current = recorder;
            recorder.start(1000); // âœ… 1ì´ˆë§ˆë‹¤ ondataavailable í˜¸ì¶œ
            setRecording(true);
            console.log('ğŸ™ï¸ MediaRecorder ì‹œì‘ë¨:', recorder);
        } catch (err) {
            alert('ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
            console.error('âŒ ë§ˆì´í¬ ì—ëŸ¬:', err);
        }
    };



    const stop = () => {
        console.log('ğŸ›‘ MediaRecorder stop() í˜¸ì¶œë¨');
        mediaRecorderRef.current?.stop();
        clearTimers();

        if (streamRef.current) {
            streamRef.current.getTracks().forEach((track) => track.stop());
            streamRef.current = null;
            console.log('ğŸ”Œ Recorder ë‚´ ë§ˆì´í¬ stream í•´ì œ ì™„ë£Œ');
        }
    };


    const formatTime = (sec: number) => {
        const m = Math.floor(sec / 60).toString().padStart(2, '0');
        const s = (sec % 60).toString().padStart(2, '0');
        return `${m}:${s}`;
    };

    return recording ? (
        <h2 className="text-md text-gray-600 mt-2">
            ğŸ™ï¸ ë…¹ìŒ ì¤‘... <strong>{formatTime(elapsedTime)}</strong> / {formatTime(maxDuration)}
        </h2>
    ) : null;
});

export default Recorder;
